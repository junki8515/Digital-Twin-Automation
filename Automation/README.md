

# Digital Twin & Automation
# Classification of 7 facial expressions & Drawing face emoticons with Manipulator

<br/><br/>
## Introduction
이 Repository는 2022년도 1학기에 Digital Twin & Automation 수업의 Automation Part의 내용입니다.

우리는 카메라를 통해 사용자를 **7가지의 표정으로 분석**하고, manipulator를 활용하여 분석한 감정에 해당하는 **이모티콘을 그려주는** 프로젝트를 진행했습니다.

<br/>

## Overview

**WIFI 연결**이 가능한 노트북 or 데스크탑이여야 하며, 이 프로젝트에서 사용한 노트북의 사양은 CPU - Intel(R) Core(TM) i7-9750H, RAM - 16GB, Graphic Card - NVIDIA GeForce RTX 2060 입니다.
**INDY-10 전용 태블릿**은 로봇 연결 및 상태 확인, 모드 변경을 통한 좌표 추출 등 프로젝트 수행 시 매우 유용한 도구입니다.
Deep Learning 모델의 Input Data 취득을 위해 **WebCam**이 필요합니다. 본 프로젝트에서는 QR 코드를 읽기 위해 노트북 외장 웹캠을 사용했습니다.
<br/>

## Requirements
**WIFI 연결**이 가능한 노트북 or 데스크탑이여야 하며, 이 프로젝트에서 사용한 노트북의 사양은 CPU - Intel(R) Core(TM) i7-9750H, RAM - 16GB, Graphic Card - NVIDIA GeForce RTX 2060 입니다.
**INDY-10 전용 태블릿**은 로봇 연결 및 상태 확인, 모드 변경을 통한 좌표 추출 등 프로젝트 수행 시 매우 유용한 도구입니다.
Deep Learning 모델의 Input Data 취득을 위해 **WebCam**이 필요합니다. 본 프로젝트에서는 QR 코드를 읽기 위해 노트북 외장 웹캠을 사용했습니다.
<br/>
## Contents
* ### Tutorial for Indy Hardware & Gripper Setting
  * [Reference Link](https://github.com/Yjinsu/Digital_Twin_and_Automation/blob/main/Project%232/md_files/Tutorial%20-%20Manipulator%20INDY-10%20%26%20Gripper%20VGC10.md)


* ### Tutorial for project implementation (Pick and Place using QR Code)
  * [Reference Link](https://github.com/Yjinsu/Digital_Twin_and_Automation/blob/main/Project%232/md_files/Tutorial%20-%20%EC%9A%B0%ED%8E%B8%20%EB%B6%84%EB%A5%98%20%EA%B3%B5%EC%A0%95%20(Pick%20%26%20Place%20using%20QR%20Code).md)

